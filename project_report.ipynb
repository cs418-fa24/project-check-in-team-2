{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethereum Blockchain Transaction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to GitHub Repository\n",
    "https://github.com/cs418-fa24/project-check-in-team-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Introduction\n",
    "In this project, we are analyzing Ethereum blockchain transaction data to investigate trends and insights related to recent transactions.\n",
    "Our primary focus is to explore transaction patterns, fees, and the frequency of various transaction types to gain a deeper understanding of blockchain dynamics.\n",
    "\n",
    "This analysis involves collecting recent transactions, cleaning the data, performing exploratory data analysis (EDA), and applying machine learning techniques to gain insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Questions:\n",
    "1. What patterns or trends can be identified in Ethereum transactions?\n",
    "2. Are there specific metrics that can help predict Ethereum price movements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to Project Scope\n",
    "Since the initial proposal, we have made the following changes:\n",
    "- **Scope Addition**: We have included a deeper analysis of transaction fees and patterns by block height to identify temporal patterns.\n",
    "- **Scope Reduction**: We initially planned to analyze more historical data; however, we have limited the scope to recent blocks due to time constraints.\n",
    "\n",
    "These adjustments will allow us to focus on recent trends and complete the analysis within the project timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection (Etherscan)\n",
    "**Data Source:** The data is collected from [Etherscan.io](https://etherscan.io/txs) using Selenium, focusing on transaction hashes, block numbers, timestamps, addresses, and fees.\n",
    "\n",
    "**Initial Observations:** The collected data includes transactional attributes that enable an analysis of transaction patterns, including frequency, transaction values, and fees.\n",
    "\n",
    "\n",
    "Using Selenium, we automate the collection of transaction data, specifically gathering transaction hashes, block numbers, timestamps, addresses, and fees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/sanmithashetty/Library/Python/3.12/lib/python/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/sanmithashetty/Library/Python/3.12/lib/python/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/sanmithashetty/Library/Python/3.12/lib/python/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/sanmithashetty/Library/Python/3.12/lib/python/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, typing_extensions, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.26.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 typing_extensions-4.12.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have disabled the data collection process by commenting it out, as the data has already been saved in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize WebDriver\n",
    "# driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Navigate to the blocks page to retrieve the latest block ID\n",
    "# driver.get(\"https://etherscan.io/blocks\")\n",
    "# time.sleep(1)\n",
    "# lastBlock = driver.find_element(by=By.XPATH, value=\"//*[@id=\\\"content\\\"]/section[2]/div[2]/div[2]/table/tbody/tr[1]/td[1]/a\")\n",
    "# lastBlockID = int(lastBlock.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate URLs for the last 20 blocks\n",
    "# blockURLs = []\n",
    "# for blockID in range(lastBlockID, lastBlockID-20, -1):\n",
    "#     blockURLs.append(\"https://etherscan.io/txs?block=\" + str(blockID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to read each row's data in the transactions table\n",
    "# def readRow(rowIndex):\n",
    "#     row = {}\n",
    "#     xPath = \"//*[@id=\\\"ContentPlaceHolder1_divTransactions\\\"]/div[2]/table/tbody/tr[\" + str(rowIndex) + \"]/\"\n",
    "#     row[\"txnHash\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[2]/div/span/a\").text\n",
    "#     row[\"method\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[3]/span\").text\n",
    "#     row[\"block\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[4]/a\").text\n",
    "#     row[\"age\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[6]/span\").text\n",
    "#     row[\"from\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[8]/div/a[1]\").get_attribute(\"href\").split(\"/\")[-1]\n",
    "#     row[\"to\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[10]/div\").find_elements(by=By.CSS_SELECTOR, value=\"a\")[-1].get_attribute(\"data-clipboard-text\")\n",
    "#     row[\"value\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[11]/span\").text\n",
    "#     row[\"txnFee\"] = driver.find_element(by=By.XPATH, value=xPath + \"td[12]\").text\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We used time.sleep(1) to avoid being blocked by the website.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collect data for each block\n",
    "# table = []\n",
    "# for blockUrl in tqdm(blockURLs, desc=\"Collecting Data Blocks (\"):\n",
    "#     driver.get(blockUrl)\n",
    "#     tranCount = int(driver.find_element(by=By.XPATH, value=\"//*[@id=\\\"ContentPlaceHolder1_divDataInfo\\\"]/div/div[1]/span\").text.split(\" \")[3])\n",
    "#     pageCount = math.ceil(tranCount / 50)\n",
    "#     for pageIndex in range(1, pageCount + 1):\n",
    "#         url = blockUrl + \"&p=\" + str(pageIndex)\n",
    "#         driver.get(url)\n",
    "#         time.sleep(1)\n",
    "#         rowBound = (tranCount - (pageCount - 1) * 50 + 1) if (pageIndex == pageCount) else 51\n",
    "#         for rowIndex in range(1, rowBound):\n",
    "#             table.append(readRow(rowIndex))\n",
    "#     time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We're creating a CSV file to use later, so we don't have to run this code again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and save to CSV\n",
    "# dataFrame = pd.DataFrame(table)\n",
    "# dataFrame.to_csv(\"DataFrame.csv\", index=False)\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
